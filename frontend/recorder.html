<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>MediVoice - Virtual Health Assistant</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 20px;
    }

    .container {
      background: white;
      border-radius: 24px;
      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
      max-width: 500px;
      width: 100%;
      padding: 40px 30px;
      text-align: center;
    }

    .header {
      margin-bottom: 30px;
    }

    .doctor-icon {
      width: 80px;
      height: 80px;
      margin: 0 auto 16px;
      background: linear-gradient(135deg, #0066cc 0%, #0052a3 100%);
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      box-shadow: 0 4px 12px rgba(0, 102, 204, 0.3);
    }

    .doctor-icon svg {
      width: 45px;
      height: 45px;
      fill: white;
    }

    h1 {
      font-size: 28px;
      color: #1a1a1a;
      font-weight: 600;
      margin-bottom: 8px;
    }

    .subtitle {
      color: #666;
      font-size: 14px;
      line-height: 1.5;
    }

    .nav-actions {
      margin-top: 14px;
      display: flex;
      justify-content: center;
    }

    .nav-link {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 10px 16px;
      border-radius: 999px;
      text-decoration: none;
      background: linear-gradient(135deg, #0066cc 0%, #0052a3 100%);
      color: white;
      font-size: 13px;
      font-weight: 600;
      box-shadow: 0 6px 16px rgba(0, 102, 204, 0.3);
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }

    .nav-link:hover {
      transform: translateY(-1px);
      box-shadow: 0 10px 20px rgba(0, 102, 204, 0.35);
    }

    .disclaimer {
      background: #fff3cd;
      border-left: 4px solid #ffc107;
      padding: 12px 16px;
      margin: 20px 0;
      text-align: left;
      border-radius: 4px;
      font-size: 13px;
      color: #856404;
    }

    .mic-section {
      margin: 40px 0;
      position: relative;
    }

    .status-text {
      font-size: 16px;
      color: #666;
      margin-bottom: 24px;
      min-height: 24px;
      font-weight: 500;
    }

    .status-text.recording {
      color: #dc3545;
    }

    .status-text.processing {
      color: #0066cc;
    }

    .mic-button {
      width: 140px;
      height: 140px;
      border-radius: 50%;
      border: none;
      background: linear-gradient(135deg, #0066cc 0%, #0052a3 100%);
      cursor: pointer;
      position: relative;
      transition: all 0.3s ease;
      box-shadow: 0 8px 24px rgba(0, 102, 204, 0.4);
      margin: 0 auto;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .mic-button:hover {
      transform: scale(1.05);
      box-shadow: 0 12px 32px rgba(0, 102, 204, 0.5);
    }

    .mic-button:active {
      transform: scale(0.95);
    }

    .mic-button.recording {
      background: linear-gradient(135deg, #dc3545 0%, #c82333 100%);
      animation: pulse 1.5s ease-in-out infinite;
    }

    .mic-button.processing {
      background: linear-gradient(135deg, #28a745 0%, #218838 100%);
      animation: spin 1s linear infinite;
    }

    .mic-button svg {
      width: 60px;
      height: 60px;
      fill: white;
    }

    @keyframes pulse {
      0%, 100% {
        box-shadow: 0 8px 24px rgba(220, 53, 69, 0.4), 0 0 0 0 rgba(220, 53, 69, 0.7);
      }
      50% {
        box-shadow: 0 8px 24px rgba(220, 53, 69, 0.4), 0 0 0 20px rgba(220, 53, 69, 0);
      }
    }

    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }

    .instruction {
      margin-top: 24px;
      font-size: 14px;
      color: #888;
      padding: 0 20px;
    }

    .result-section {
      margin-top: 24px;
      text-align: left;
    }

    .result-title {
      font-size: 16px;
      font-weight: 600;
      color: #1a1a1a;
      margin-bottom: 12px;
      display: flex;
      align-items: center;
      gap: 8px;
    }


    .result-content {
      background: #f8f9fa;
      border: 1px solid #e0e0e0;
      border-radius: 12px;
      padding: 16px;
      white-space: pre-wrap;
      word-break: break-word;
      font-size: 13px;
      color: #333;
      line-height: 1.6;
      max-height: 300px;
      overflow-y: auto;
      display: none;
    }

    .result-content.show {
      display: block;
    }

    .result-content.success {
      border-left: 4px solid #28a745;
    }


     .result-content.error {
       border-left: 4px solid #dc3545;
       background: #fff5f5;
     }

     .redaction-notice {
       background: #e8f4f8;
       border-left: 4px solid #17a2b8;
       padding: 12px;
       margin-bottom: 16px;
       border-radius: 4px;
       font-size: 12px;
       color: #0c5460;
     }

     .redaction-notice strong {
       display: block;
       margin-bottom: 6px;
     }

     .redaction-tags {
       display: flex;
       flex-wrap: wrap;
       gap: 6px;
       margin-top: 8px;
     }

     .redaction-tag {
       background: #d4edda;
       color: #155724;
       padding: 4px 10px;
       border-radius: 12px;
       font-size: 11px;
       font-weight: 500;
     }

    .waves {
      display: none;
      justify-content: center;
      align-items: center;
      gap: 4px;
      margin-top: 16px;
    }

    .waves.show {
      display: flex;
    }

    .wave {
      width: 4px;
      height: 20px;
      background: #0066cc;
      border-radius: 2px;
      animation: wave 1s ease-in-out infinite;
    }

    .wave:nth-child(2) { animation-delay: 0.1s; }
    .wave:nth-child(3) { animation-delay: 0.2s; }
    .wave:nth-child(4) { animation-delay: 0.3s; }
    .wave:nth-child(5) { animation-delay: 0.4s; }

    @keyframes wave {
      0%, 100% { height: 20px; }
      50% { height: 40px; }
    }

    .audio-level {
      display: none;
      justify-content: center;
      align-items: center;
      gap: 3px;
      margin-top: 16px;
    }

    .audio-level.show {
      display: flex;
    }

    .level-bar {
      width: 3px;
      height: 8px;
      background: #28a745;
      border-radius: 1px;
      transition: height 0.05s ease;
    }

    .recording-timer {
      font-size: 18px;
      font-weight: bold;
      color: #dc3545;
      margin-top: 12px;
      display: none;
      min-height: 24px;
    }

    .recording-timer.show {
      display: block;
    }

    .examples-section {
      margin: 30px 0;
      padding: 20px;
      background: #f0f4ff;
      border-radius: 12px;
      text-align: left;
    }

    .examples-title {
      font-size: 14px;
      font-weight: 600;
      color: #1a1a1a;
      margin-bottom: 12px;
    }

    .example-buttons {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 8px;
    }

    .example-btn {
      background: white;
      border: 1px solid #e0e0e0;
      border-radius: 8px;
      padding: 10px;
      font-size: 12px;
      cursor: pointer;
      transition: all 0.2s ease;
      color: #333;
      font-weight: 500;
    }

    .example-btn:hover {
      background: #e3f2fd;
      border-color: #0066cc;
    }

    .example-btn:active {
      transform: scale(0.98);
    }


    @media (max-width: 600px) {
      .container {
        padding: 30px 20px;
      }

      h1 {
        font-size: 24px;
      }

      .mic-button {
        width: 120px;
        height: 120px;
      }

      .mic-button svg {
        width: 50px;
        height: 50px;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <div class="doctor-icon">
        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
          <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 3c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm0 14.2c-2.5 0-4.71-1.28-6-3.22.03-1.99 4-3.08 6-3.08 1.99 0 5.97 1.09 6 3.08-1.29 1.94-3.5 3.22-6 3.22z"/>
        </svg>
      </div>
      <h1>MediVoice Assistant</h1>
      <p class="subtitle">Virtual Pharmacist Triage Assistant</p>
      <div class="nav-actions">
        <a class="nav-link" href="/dashboard">Dashboard</a>
      </div>
    </div>

    <div class="disclaimer">
      <strong>‚ö†Ô∏è Important Notice:</strong> This is a demonstration tool for pharmacist triage. It does not provide medical advice.
    </div>

    <div class="examples-section">
      <div class="examples-title">üìù Try with pre-recorded examples:</div>
      <div class="example-buttons">
        <button class="example-btn" onclick="sendExample('I stopped taking metformin because it makes me dizzy')">Dizziness & Metformin</button>
        <button class="example-btn" onclick="sendExample('I have chest pain and shortness of breath for 2 days')">üö® Chest Pain</button>
        <button class="example-btn" onclick="sendExample('I ran out of lisinopril last week, should I reorder or just wait')">Adherence Question</button>
        <button class="example-btn" onclick="sendExample('New rash appeared after starting the antibiotic yesterday')">Rash/Side Effect</button>
      </div>
    </div>

    <div class="mic-section">
      <div id="status" class="status-text">Click the microphone to start recording</div>
      
      <button id="micButton" class="mic-button">
        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
          <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
          <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
        </svg>
      </button>

      <div id="waves" class="waves">
        <div class="wave"></div>
        <div class="wave"></div>
        <div class="wave"></div>
        <div class="wave"></div>
        <div class="wave"></div>
      </div>

      <div id="audioLevel" class="audio-level">
        <div class="level-bar" style="height: 8px;"></div>
        <div class="level-bar" style="height: 12px;"></div>
        <div class="level-bar" style="height: 15px;"></div>
        <div class="level-bar" style="height: 12px;"></div>
        <div class="level-bar" style="height: 8px;"></div>
      </div>

      <div id="recordingTimer" class="recording-timer">‚è±Ô∏è 0:00</div>

      <p class="instruction">
        üí° Example: "I stopped taking metformin because it makes me dizzy"
      </p>
    </div>


 <div class="result-section">
   <div class="result-title">
     <svg width="20" height="20" viewBox="0 0 24 24" fill="#0066cc" xmlns="http://www.w3.org/2000/svg">
       <path d="M19 3h-4.18C14.4 1.84 13.3 1 12 1c-1.3 0-2.4.84-2.82 2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm-7 0c.55 0 1 .45 1 1s-.45 1-1 1-1-.45-1-1 .45-1 1-1zm0 4c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm6 12H6v-1.4c0-2 4-3.1 6-3.1s6 1.1 6 3.1V19z"/>
     </svg>
     Analysis Result
   </div>
   <div id="redactionNotice" class="redaction-notice" style="display: none;"></div>
   <div id="result" class="result-content"></div>
 </div>
  </div>

<script>
  let mediaRecorder;
  let chunks = [];
  let audioStream = null;
  let analyser = null;
  let animationId = null;
  let recordingStartTime = null;
  let timerInterval = null;
  let peakAudioLevel = 0;
  let isRecording = false;
  let streamTimeoutId = null;
  const audioContext = new (window.AudioContext || window.webkitAudioContext)();
  const MIN_RECORDING_TIME_MS = 1500; // Minimum 1.5 seconds
  const MIN_AUDIO_LEVEL = 2; // Minimum average audio level (0-255 scale)
  const MIN_FILE_SIZE = 2000; // Minimum 2KB

  const micButton = document.getElementById('micButton');
  const status = document.getElementById('status');
  const result = document.getElementById('result');
  const waves = document.getElementById('waves');
  const audioLevel = document.getElementById('audioLevel');
  const recordingTimer = document.getElementById('recordingTimer');

  function updateStatus(text, state = '') {
    status.textContent = text;
    status.className = 'status-text ' + state;
  }


 function showResult(data, isError = false, options = {}) {
   const { stream = true } = options;
   result.className = 'result-content show ' + (isError ? 'error' : 'success');
   
  // Show redaction notice if PHI was removed
   if (!isError && data && data.redaction_tags && data.redaction_tags.length > 0) {
     redactionNotice.style.display = 'block';
     redactionNotice.innerHTML = `
       <strong>üîí Data Privacy Notice:</strong>
       Sensitive information has been redacted:
       <div class="redaction-tags">
         ${data.redaction_tags.map(tag => `<span class="redaction-tag">${tag}</span>`).join('')}
       </div>
     `;
   } else {
     redactionNotice.style.display = 'none';
   }
   
   if (typeof data === 'string' || isError || !stream) {
     result.textContent = typeof data === 'string' ? data : JSON.stringify(data, null, 2);
     return;
   }
   
   // Stream-like effect: show result with slight animation
   streamResultToUI(data);
 }
  function streamResultToUI(data) {
    if (typeof data === 'string') return;
    
    if (streamTimeoutId) {
      clearTimeout(streamTimeoutId);
      streamTimeoutId = null;
    }
    
    // Clear and rebuild with streaming effect
    result.textContent = '';
    const json = JSON.stringify(data, null, 2);
    let idx = 0;
    
    const streamChar = () => {
      if (idx < json.length) {
        result.textContent += json[idx];
        idx++;
        streamTimeoutId = setTimeout(streamChar, 5);
      } else {
        streamTimeoutId = null;
      }
    };
    streamChar();
  }

  const redactionNotice = document.getElementById('redactionNotice');

  function hideResult() {
    result.className = 'result-content';
  }

  function resetRecorderUI() {
    hideResult();
    result.textContent = '';
    updateStatus('Click the microphone to start recording');
    redactionNotice.style.display = 'none';
  }

  function startAudioLevelMonitoring() {
    if (!analyser) return;
    
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    const levelbars = audioLevel.querySelectorAll('.level-bar');
    peakAudioLevel = 0;
    
    const updateLevels = () => {
      analyser.getByteFrequencyData(dataArray);
      const avg = dataArray.reduce((a, b) => a + b) / dataArray.length;
      const normalized = Math.min(40, (avg / 255) * 40);
      
      // Track peak level during recording (keep on 0-255 scale)
      peakAudioLevel = Math.max(peakAudioLevel, avg);
      
      levelbars.forEach((bar, i) => {
        const offset = ((i - 2) * 5);
        const height = Math.max(4, normalized + offset);
        bar.style.height = height + 'px';
      });
      
      animationId = requestAnimationFrame(updateLevels);
    };
    updateLevels();
  }

  function stopAudioLevelMonitoring() {
    if (animationId) {
      cancelAnimationFrame(animationId);
      animationId = null;
    }
  }

  function startRecordingTimer() {
    recordingStartTime = Date.now();
    recordingTimer.classList.add('show');
    
    timerInterval = setInterval(() => {
      const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
      const mins = Math.floor(elapsed / 60);
      const secs = elapsed % 60;
      recordingTimer.textContent = `‚è±Ô∏è ${mins}:${secs.toString().padStart(2, '0')}`;
    }, 100);
  }

  function stopRecordingTimer() {
    if (timerInterval) {
      clearInterval(timerInterval);
      timerInterval = null;
    }
    recordingTimer.classList.remove('show');
  }



  async function startRecording() {
    try {
      chunks = [];
      hideResult();
      updateStatus('üéôÔ∏è Recording... Click to stop', 'recording');
      
      micButton.classList.add('recording');
      waves.classList.add('show');
      audioLevel.classList.add('show');
      isRecording = true;

      audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const source = audioContext.createMediaStreamSource(audioStream);
      analyser = audioContext.createAnalyser();
      source.connect(analyser);

      mediaRecorder = new MediaRecorder(audioStream, { mimeType: 'audio/webm' });

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunks.push(e.data);
      };

      mediaRecorder.onstop = async () => {
        stopAudioLevelMonitoring();
        stopRecordingTimer();
        const blob = new Blob(chunks, { type: 'audio/webm' });
        await sendAudio(blob);
        
        if (audioStream) {
          audioStream.getTracks().forEach(track => track.stop());
          audioStream = null;
        }
      };

      mediaRecorder.start();
      startAudioLevelMonitoring();
      startRecordingTimer();
    } catch (error) {
      console.error('Error starting recording:', error);
      updateStatus('‚ùå Error accessing microphone');
      micButton.classList.remove('recording');
      waves.classList.remove('show');
      audioLevel.classList.remove('show');
      isRecording = false;
      showResult('Error: Could not access microphone. Check permissions.', true);
    }
  }

  function stopRecordingAndAnalyze() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      updateStatus('‚è≥ Analyzing audio...', 'processing');
      micButton.classList.remove('recording');
      micButton.classList.add('processing');
      waves.classList.remove('show');
      audioLevel.classList.remove('show');
      isRecording = false;
      mediaRecorder.stop();
    }
  }

  async function handleMicButtonClick() {
    if (!isRecording) {
      await startRecording();
    } else {
      stopRecordingAndAnalyze();
    }
  }

  async function sendAudio(blob) {
    try {
      // Validation: Check file size
      if (blob.size < MIN_FILE_SIZE) {
        micButton.classList.remove('processing');
        updateStatus('‚ùå Recording too quiet or too short');
        showResult(
          `Error: Recording appears to be empty or too quiet.\n\nSuggestions:\n` +
          `‚Ä¢ Check microphone permissions\n` +
          `‚Ä¢ Record for at least 2 seconds\n` +
          `‚Ä¢ Speak clearly into the microphone\n` +
          `‚Ä¢ Ensure volume is not muted\n\n` +
          `Current: ${blob.size} bytes (need > 5000)`,
          true
        );
        resetUI();
        return;
      }

      // Validation: Check if peak audio level is too low
      if (peakAudioLevel < MIN_AUDIO_LEVEL) {
        micButton.classList.remove('processing');
        updateStatus('‚ùå No sound detected');
        showResult(
          `Error: Microphone didn't pick up clear audio.\n\n` +
          `‚Ä¢ Check if microphone is working\n` +
          `‚Ä¢ Grant browser permission to use microphone\n` +
          `‚Ä¢ Speak louder or closer to mic\n` +
          `‚Ä¢ Try using a different microphone\n\n` +
          `Tip: Watch the green bars on the left when recording.`,
          true
        );
        resetUI();
        return;
      }

      const form = new FormData();
      form.append('audio', blob, 'recording.webm');

      const res = await fetch('/voice-intake', { 
        method: 'POST', 
        body: form 
      });

      const data = await res.json();
      
      micButton.classList.remove('processing');
      
      if (!res.ok) {
        throw new Error(data.detail || `HTTP error! status: ${res.status}`);
      }

      updateStatus('‚úÖ Analysis complete - Ready to record again');
      showResult(data, false);
      resetUI();

    } catch (error) {
      console.error('Error sending audio:', error);
      micButton.classList.remove('processing');
      updateStatus('‚ùå Analysis error - Try again');
      showResult(`Error: ${error.message}\n\nPlease verify the server is running.`, true);
      resetUI();
    }
  }

  function resetUI() {
    setTimeout(() => {
      updateStatus('Click the microphone to start recording');
      peakAudioLevel = 0;
    }, 3000);
  }

  async function sendExample(transcript) {
    updateStatus('‚è≥ Processing example...', 'processing');
    micButton.classList.add('processing');
    hideResult();

    try {
      const res = await fetch('/voice-intake-example', { 
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ transcript })
      });

      const data = await res.json();
      
      micButton.classList.remove('processing');
      
      if (!res.ok) {
        throw new Error(data.detail || `HTTP error! status: ${res.status}`);
      }

      updateStatus('‚úÖ Analysis complete - Ready to record again');
      showResult(data, false);
      resetUI();

    } catch (error) {
      console.error('Error:', error);
      micButton.classList.remove('processing');
      updateStatus('‚ùå Error');
      showResult(`Error: ${error.message}`, true);
      resetUI();
    }
  }

  // Click to toggle recording on/off
  micButton.addEventListener('click', handleMicButtonClick);

  // Touch support for mobile
  micButton.addEventListener('touchstart', (e) => {
    e.preventDefault();
  });

  micButton.addEventListener('touchend', (e) => {
    e.preventDefault();
    handleMicButtonClick();
  });

  // Reset state on load and when returning to the tab
  window.addEventListener('load', resetRecorderUI);
  document.addEventListener('visibilitychange', () => {
    if (document.visibilityState === 'visible') {
      resetRecorderUI();
      if (audioStream) {
        audioStream.getTracks().forEach(track => track.stop());
        audioStream = null;
      }
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        try { mediaRecorder.stop(); } catch (e) {}
      }
      micButton.classList.remove('recording', 'processing');
      waves.classList.remove('show');
      audioLevel.classList.remove('show');
      stopAudioLevelMonitoring();
      stopRecordingTimer();
      isRecording = false;
    }
  });

</script>
</body>
</html>
